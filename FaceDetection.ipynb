{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdd1cf5-9262-4646-91ca-01f3e7683f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e9cbc0-f219-4825-a43d-a20e583c030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.CascadeClassifier(path) ; class is use to load curent working directory model in cv2\n",
    "faceModel=cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")    #load predifined model from current working directory \n",
    "\n",
    "                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bcf8b8-d150-43cf-9d28-711190c00a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(\"C:/Users/Lenovo/Desktop/Machine learning Ass and project/class-25(Project-2 -face detection project in computer vision)/images/Virushka .jpg\") #image read by default in color mode \n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)        #convert it into gray during pass image for better efficiancy\n",
    "\n",
    "faces=faceModel.detectMultiScale(gray)           #faceModel.detectMultiScale(gray)  :_it is use to predict image object face\n",
    "                                                                                     #:detect face into nested list [x,y,h,w]\n",
    "for face in faces:\n",
    "    print(face)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73867845-b5f9-46f0-9abe-b7ee4c5eb57d",
   "metadata": {},
   "source": [
    "=========>detect face [x-axis,y-axis,hight,width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3d16c2-6f52-47fd-a79f-7993a534a8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for another image\n",
    "img=cv2.imread(\"C:/Users/Lenovo/Desktop/Machine learning Ass and project/class-25(Project-2 -face detection project in computer vision)/images/legend.jpg\")\n",
    "\n",
    "\n",
    "print(type(img))\n",
    "\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "faces=faceModel.detectMultiScale(gray)\n",
    "\n",
    "for x,y,w,h in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "\n",
    "cv2.imshow(\"face detection\",img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca36269-28a7-4e9f-a902-185414c29a5e",
   "metadata": {},
   "source": [
    "\n",
    "===> here detection has image miss classification problem exist so tune \"detectMultiScale\" object with minNeighbots,scaleFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93ed498-b42d-4933-a08d-9e3ea26b5280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#or----\n",
    "img=cv2.imread(\"C:/Users/Lenovo/Desktop/Machine learning Ass and project/class-25(Project-2 -face detection project in computer vision)/images/legend.jpg\")\n",
    "\n",
    "\n",
    "print(type(img))\n",
    "\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "faces=faceModel.detectMultiScale(gray,minNeighbors=6,scaleFactor=1.3)       #scaleFactor;- is use to scale whole image  with bounded box, 1.05 is good scaling value in sliding window\n",
    "                                                                            #minNeighbors:-it is no. of bounded box where face exist during checking face in sliding window\n",
    "                                                                            #minsize: size of face to detect\n",
    "                                                                            #maxsize;max size of face to detect\n",
    "for x,y,w,h in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "\n",
    "cv2.imshow(\"face detection\",img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fdf703cf-7949-498e-9b15-25a35ab033f8",
   "metadata": {},
   "source": [
    "==>above face detection is for image now we will work with web cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d3efe1-89de-4dfc-803c-37f6bd227681",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdo=cv2.VideoCapture(0) #web cam\n",
    "\n",
    "faceModel=cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "while True:\n",
    "    flag,frame=vdo.read()\n",
    "    if flag==False:\n",
    "        break\n",
    "    cv2.putText(frame,\"press 'c' to cancel!\",(10,30),cv2.FONT_HERSHEY_PLAIN,2,(0,0,255),2)\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces=faceModel.detectMultiScale(gray,minNeighbors=8)\n",
    "    for x,y,w,h in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        \n",
    "    cv2.imshow(\"vdo\",frame)\n",
    "    \n",
    "    key=cv2.waitKey(25)\n",
    "    if key==ord('c'):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "vdo.release()             #after  one by one  detect frame it will release for next frame and detect another frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7742f8f1-a840-497c-ab74-4ebc88f3efd8",
   "metadata": {},
   "source": [
    "   ->this is face detection with web cam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fddebb0-a070-424e-90f4-ca52dfb00f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f538ed6c-e80b-4e62-b0e6-015982d69c23",
   "metadata": {},
   "source": [
    "# student attendence system using face detection   ===>>>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1b58d4-e6f2-411d-a80f-14a7033a2db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read image capture face (crop) and save it into current working directory\n",
    "\n",
    "img=cv2.imread(\"C:/Users/Lenovo/Desktop/Machine learning Ass and project/class-25(Project-2 -face detection project in computer vision)/images/legend.jpg\")\n",
    "\n",
    "\n",
    "print(type(img))\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces=faceModel.detectMultiScale(gray,minNeighbors=6,scaleFactor=1.3)\n",
    "for x,y,w,h in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "      \n",
    "    face=img[y:y+h,x:x+w]                               #crop the image face \n",
    "    cv2.imwrite(\"sachin_face.jpg\",face)                 #save it into current working dir.\n",
    "    \n",
    "cv2.imshow(\"face detection\",img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbb843c-c9a9-43df-ac8b-98e38124dd44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2800ff8d-1715-486c-9c00-1dd2a0607b3b",
   "metadata": {},
   "source": [
    "==>for attendence of student we have requairment of A student multiple types of images for train model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df9364e-0053-4df8-b3de-fc057efc1b89",
   "metadata": {},
   "source": [
    "### with web camera   first capture images of student and save it into folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584148a8-17b2-4e1b-8657-2f09e1e9b8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with web camera   first capture images of student and save it into folder\n",
    "\n",
    "#=> captue diff-2 student images and store it into diff diff folder\n",
    "\n",
    "import cv2\n",
    "vdo=cv2.VideoCapture(0) #web cam\n",
    "faceModel=cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "i=1\n",
    "while True:\n",
    "    flag,frame=vdo.read()\n",
    "    if flag==False:\n",
    "        break\n",
    "    cv2.putText(frame,\"press 'c' to cancel!\",(10,30),cv2.FONT_HERSHEY_PLAIN,2,(0,0,255),2)\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces=faceModel.detectMultiScale(gray,minNeighbors=6)\n",
    "    for x,y,w,h in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        \n",
    "        face=frame[y:y+h,x:x+w]\n",
    "        \n",
    "       #cv2.imwrite(f\"students/kushal/img_{i}.jpg\",face)            #student kushal images \n",
    "        cv2.imwrite(f\"students/rohit/img_{i}.jpg\",face)\n",
    "        \n",
    "        i+=1 \n",
    "        \n",
    "    cv2.imshow(\"vdo\",frame)\n",
    "    key=cv2.waitKey(25)\n",
    "    if key==ord('c'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "vdo.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4b5473-7e67-4818-b5d5-1f98d9b14e75",
   "metadata": {},
   "source": [
    "==>here we will capture kushal and rohit student images and save in kushal&rohit folder, similarly we can cature any student images and store in folder for model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce46899-8813-4247-aa35-cda6e49c87ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOW;-> preprocessing the images for train==>\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1cda1f-1105-42d7-8697-6b6851dbf671",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read images of kushal(class-1)\n",
    "\n",
    "X=[]  #feature\n",
    "y=[]  #target\n",
    "images=os.listdir(\"students/kushal/\")    #from given directory\n",
    "for img in images:\n",
    "    img_clr=cv2.imread(f\"students/kushal/{img}\")   #read imges\n",
    "    #print(img_clr.shape)\n",
    "    img_gray=cv2.cvtColor(img_clr,cv2.COLOR_BGR2GRAY)  #convert image into grayscale\n",
    "    #print(img_gray.shape)\n",
    "    img_gray=cv2.resize(img_gray,(100,100))  #resize images\n",
    "    img_gray=img_gray.flatten()       #image 2d to 1d array\n",
    "    img_gray=img_gray/255             #scalle the image\n",
    "    X.append(img_gray)           \n",
    "    y.append(\"students/kushal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ae53c0-1341-4ecd-a07c-10b1177a93c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7ad59c-34bb-472b-bf43-ca103ccd0de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read images of rohit(class-2)\n",
    "\n",
    "\n",
    "images=os.listdir(\"students/rohit/\")    #from given directory\n",
    "for img in images:\n",
    "    img_clr=cv2.imread(f\"students/rohit/{img}\")   #read imges\n",
    "    #print(img_clr.shape)\n",
    "    img_gray=cv2.cvtColor(img_clr,cv2.COLOR_BGR2GRAY)  #convert image into grayscale\n",
    "    #print(img_gray.shape)\n",
    "    img_gray=cv2.resize(img_gray,(100,100))  #resize images\n",
    "    img_gray=img_gray.flatten()       #image 2d to 1d array\n",
    "    img_gray=img_gray/255             #scalle the image\n",
    "    X.append(img_gray)           \n",
    "    y.append(\"students/rohit\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c63a071-2d09-4ed3-8b7a-db674eef444a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a39c1c-69be-4119-b9f2-4d7a6cb11f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbe70b4-712c-467e-836d-9f4a3518ef08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOw->create model and train the model\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a548d6-54e8-40aa-b8a1-a362535e894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LogisticRegression()\n",
    "model.fit(X,y)           #now model is trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d9a238-5ab8-4f7f-8996-9482d39de1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOW predict the model\n",
    "X_test=[]\n",
    "\n",
    "test_img=cv2.imread(\"students/kushal/img_36.jpg\")  #read image for prediction\n",
    "\n",
    "img_gray=cv2.cvtColor(test_img,cv2.COLOR_BGR2GRAY)       #preprocessing the predictive images\n",
    "img_gray=cv2.resize(img_gray,(100,100))\n",
    "img_gray=img_gray.flatten()\n",
    "img_gray=img_gray/255\n",
    "X_test.append(img_gray)      #append it into X_test list\n",
    "\n",
    "print(model.predict_proba(X_test))     #predictive probability(check confidence score)\n",
    "print(model.predict(X_test))          #predict the class of image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7147f696-3319-431f-8ad1-100a8a7cf779",
   "metadata": {},
   "source": [
    "===>so here we can see the confidence score of model and the class of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4564fcd4-85e3-4097-bf45-1f9eeaa67d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#and->\n",
    "X_test=[]\n",
    "\n",
    "test_img=cv2.imread(\"students/rohit/img_10.jpg\")\n",
    "\n",
    "img_gray=cv2.cvtColor(test_img,cv2.COLOR_BGR2GRAY)\n",
    "img_gray=cv2.resize(img_gray,(100,100))\n",
    "img_gray=img_gray.flatten()\n",
    "img_gray=img_gray/255\n",
    "\n",
    "X_test.append(img_gray)\n",
    "\n",
    "print(model.predict_proba(X_test))\n",
    "print(model.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fad6ee8-da26-43e4-9570-d8d65fa77e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac262506-f5bb-4802-b2c9-c3296a29d896",
   "metadata": {},
   "source": [
    "### NOW by using predict by web cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca36c4b-accf-4a39-a59e-4fa6d40d512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "vdo=cv2.VideoCapture(0) #web cam\n",
    "faceModel=cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "while True:\n",
    "    flag,frame=vdo.read()\n",
    "    if flag==False:\n",
    "        break\n",
    "    cv2.putText(frame,\"press 'c' to cancel!\",(10,30),cv2.FONT_HERSHEY_PLAIN,2,(0,0,255),2)\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces=faceModel.detectMultiScale(gray,minNeighbors=6)\n",
    "    for x,y,w,h in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        \n",
    "        face=frame[y:y+h,x:x+w]          #(image)seperate the face from capture\n",
    "        \n",
    "        X_test=[]                       #preprocessing the images\n",
    "        img_gray=cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "        img_gray=cv2.resize(img_gray,(100,100))\n",
    "        img_gray=img_gray.flatten()\n",
    "        img_gray=img_gray/255\n",
    "        X_test.append(img_gray)        \n",
    "        pred=model.predict(X_test)\n",
    "        \n",
    "        cv2.putText(frame,pred[0],(x,y-5),cv2.FONT_HERSHEY_PLAIN,2,(0,255,255),2)   #write text on images\n",
    "        \n",
    "    cv2.imshow(\"vdo\",frame)\n",
    "    key=cv2.waitKey(25)\n",
    "    if key==ord('c'):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "vdo.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8020e426-2146-4246-9a17-bcc0de6e0636",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTE;->if program not detect the name so recapture student images then run the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708d093a-c31f-4a10-86c6-9aff4d720e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
